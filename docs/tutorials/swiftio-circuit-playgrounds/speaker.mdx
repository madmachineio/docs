---
title: Play music with speaker
description: Learn how to
---

# Play music with speaker

You will make the speaker play a piece of music.

You have tried to produce sound using a buzzer. Its sound is quite sharp compared to the speaker. The speaker could produce sound with higher quality. In this chapter, you are going to enjoy the music played by the speaker.

**Learning goals**
* Learn how the speaker produces different sounds.
* Understand the difference between buzzer and speaker.
* Know about the general idea of I2S.
* Know about different sound waveforms.
* Understand the sampling of audio.
* Realize the difference between WAVE and MP3 files.

## Background

### What is I2S?

I2S, aka inter-integrated circuit sound, is usually connected to digital audio devices and is specially designed for audio application. It is a digital sound protocol to transmit the audio signal.

It uses three wires for communication:

* Serial clock (SCK) or Bit Clock (BCLK): it carries the clock signal. Its frequency equals to Sample Rate * Bits per channel * Number of channels. 
* Frame Select (FS), also called Word Select (WS): it decides if the right or left channel is used. The SYNC pin on the SwiftIO feather plays that role.
* Serial data (SD): it is used to transfer data. 

The SwiftIO Feather always serves as the master device and transmits the data to slave devices. There are two pairs of I2S interfaces: one is I2SOut, so the serial data line is TX, used to send data; the other is I2SIn, and the corresponding serial data line could only receive the audio data. The speaker needs the first one to send audio data out. 


### About audio

You listen to music in everyday life, but do you know how the audio is stored on your computer? And there are so many different file formats, what’s the difference? Let’s find out more about it.

**Waveform**

The waveforms of sound are various, and sine wave, square wave, triangle wave and sawtooth wave are the four commonly used forms. Each one sounds completely different. Their combination allows you to get special sounds. And this is how the synthesizer works.  

<img
  src={require('./img/waveforms.png').default}
  alt="Wave forms" width="960"
/>

We’ll talk about the sine wave, it is the fundamental waveform. And we only deal with periodic waveforms here. So by repeating the waves, you could get a constant sound. The frequency measures how many waves in a second, in hertz. And the higher the frequency, the higher the pitch. The frequency your ear could hear is between 20 Hz and 20000 Hz. 

**Sampling**

The sine wave constantly changes with time. To record it, there are some sampling techniques to store it digitally. Let’s take a look at pulse code modulation (PCM). It records the sound amplitude at a regular time interval. And then you would get a list of raw data. It could be converted back into the sine wave when played back in a speaker. 

<img
  src={require('./img/sampling.png').default}
  alt="Sampling" width="480"
/>

Certainly, the wave generated according to the raw data is not exactly the same as the original one. As long as the sample data are enough, you could largely recreate the original signal. 

Sample rate describes how many times the signal is sampled in one second, measured in hertz (hz). There is a known law about the rate - it should be more than twice the original sound frequency, or it will cause distortion.
Sample depth corresponds to the number of possible values between the minimum and maximum sound. It could be 8, 16 or 24-bit. Bigger one means the raw data is more accurate.

When you wear headphones, sometimes you can hear different sounds in your left and right ear. This kind of audio is called stereo. It has two channels: left channel and right channel. The two channels have different waveforms. 
Since the maximum frequency for human ears is about 20KHz, the sample rate should be double, that is, about 40KHz. The CD audio is sampled at 44,100Hz, that means there are 44100 sampled signals in a second, so this rate is widely used for all kinds of audio material. And it is usually sampled as 16-bit and has two channels. 

**Audio format**

There are many audio formats that you can see when you listen to music: mp3, wave, aac, flac… Different formats will affect the sound quality when you hear it. Wave and flac are lossless audio formats, while mp3 and aac are lossy formats. Let’s talk about the two common formats: wav and mp3.

Wave file contains not only a list of raw samples, but also a header in front to indicate the information about sampling. It stores the original audio data as they are. So the WAV file has no data loss and doesn’t require decoding. However, it is large in size as it keeps all the audio data.

MP3 files use some compression algorithms to remove some of the frequencies that human ears are not sensitive to. And to many of the listeners, this quality loss is not perceptible. Compared to the wav file, MP3 is much smaller and is really handy to download from the Internet. Since it uses compression algorithms, the file needs to be decoded to play it.  

## New component

### Speaker

The working principle of the speaker is similar to the buzzer. When the current flows, the internal diaphragm would move back and forth, thus causing the air vibration which leads to the sound you hear. The differences between speaker and buzzer lie in that the diaphragm inside a speaker would move to different positions according to the signal, so the speaker could produce multiple sounds, also, the sound is of higher quality. So the speaker is suitable to reproduce the audio signal it receives and is widely used to play music. 

Symbol: 

The speaker needs an analog signal to produce sounds. The audio info transmitted through the I2S bus is a digital signal. It is not the signal that the speaker requires, so there is an additional chip beside the speaker that could convert the digital signal to an analog signal, known as DAC. 

Even after successfully converted to an analog signal, the audio signal is not strong enough to drive a speaker and could only drive a headphone. So there comes an amplifier. It could make the signal appropriate for the speaker. In this way, the speaker finally plays the music.

Let’s find out how the audio is generated by the speaker. 

* First, you get a WAV file, not an MP3 file. The WAV file is uncompressed and stores the raw audio info, while the MP3 file adopts some technique to compress the audio and reserves the overall audio quality.  We’ll find it more in the next chapter. 
* Then the microcontroller reads the audio file and gets the data.
* The audio signal is transmitted on the I2S bus, then converted to an analog signal and amplified for the speaker. At last, you hear the music from the speaker. 

## Circuit

The speaker is connected to I2SOut0.

<img
  src={require('./img/speakerCircuit.png').default}
  alt="Speaker circuit" width="960"
/>

<img
  src={require('./img/speakerCircuitDiagram.png').default}
  alt="Speaker circuit diagram" width="360"
/>

:::note
The circuits above are simplified versions for your reference.
:::

## Preparation

Class 
I2SOut: this class is used to write audio data to external devices using I2S protocol. 
Method 
init(_ idName: IdName, rate: Int = 16_000, bits: Int = 16, channel: SampleChannel = .monoLeft,
 mode: Mode = .philips)
Initialize an I2S output interface.
The first parameter is the pin id.
The rate decides the sampling rate of the audio. The default rate is 16000 Hz.
The bits is the sampling depth of the audio. It is 16-bit by default.
There are three channels: left, right and stereo. By default, it is .monoLeft.
The mode is about different ways that define how the data is formed. The .philips is the default mode.


write(_ sample: [UInt8], count: Int? = nil, timeout: Int? = nil)
Send audio data out to devices.


## Exercise

1. Play scales with different sounds


### 1. Play scales with different sounds

Different waveforms can generate different sounds. In this exercise, you will generate a square wave and a triangle wave manually. Then play the scale using two sounds.

<img
  src={require('./img/music.png').default}
  alt="Music" width="480"
/>

**Code analysis**
You can find the complete code here. 

```swift
import SwiftIO
import SwiftIOFeather
```

Import the SwiftIO library to set I2S and the SwiftIOFeather to use pin ids.

```swift
let speaker = I2SOut(Id.I2SOut0)
```

Initialize an I2SOut interface reserved for the speaker. It will have a 16k sample rate and 16-bit sample bits by default.

```swift
let frequency: [Float] = [261.626, 293.665, 329.628, 349.228, 391.995, 440.000, 493.883]
```

Store frequencies for note C, D, E, F, G, A, B. That constitutes a scale.

```swift
let sampleRate = 16_000
let rawSampleLength = 1000
var rawSamples = [Int16](repeating: 0, count: rawSampleLength)
var amplitude: Int16 = 20_000
```

Define the parameters for the audio data: 

* The signal is sampled at 16000 Hz, so there will be 16000 data 1 second.
* rawSampleLength decides the count of samples of the generated waves. 
* rawSamples stores the samples of the audio signal. At first, all values are filled with 0 and the count is decided by rawSampleLength.
* amplitude is the difference between the minimum and maximum.

```swift
while true {

    let duration: Float = 1.0

    generateSquare(amplitude: amplitude, &rawSamples)
    for f in frequency {
        playWave(samples: rawSamples, frequency: f, duration: duration)
    } 
    sleep(ms: 1000)

    generateTriangle(amplitude: amplitude, &rawSamples)
    for f in frequency {
        playWave(samples: rawSamples, frequency: f, duration: duration)
    } 
    sleep(ms: 1000)

    amplitude -= 2000
    if amplitude <= 0 {
        amplitude = 20_000
    }
}
```

In the loop, you will always play scales. The pitch is decided by the frequencies. How the samples sound is decided by the wave form. 

The first time, it’s a square wave, the sound is like the one you hear from a buzzer. After that, it’s a triangle wave, the sound is softer and clearer.  Then the amplitude decreases and will turn down the speaker.

```swift
func generateSquare(amplitude: Int16, _ samples: inout [Int16]) {
    let count = samples.count
    for i in 0..<count / 2 {
        samples[i] = -(amplitude / 2)
    }
    for i in count / 2..<count {
        samples[i] = amplitude / 2
    }
}
```

This function allows you to generate a square wave as below. It will calculate the samples in a period and store them, thus the array samples is set as inout and can be changed inside the function. When you play the audio, the following waves just repeat these samples.

The signal just has two states, so the calculation is quite simple. The first half samples are all the minimum and the second half are all the maximum.

<img
  src={require('./img/generateSquareWave.png').default}
  alt="Generate square wave" width="720"
/>

```swift
func generateTriangle(amplitude: Int16, _ samples: inout [Int16]) {
    let count = samples.count

    let step = Float(amplitude) / Float(count)
    for i in 0..<count / 4{
        samples[i] = Int16(step * Float(i))
    }
    for i in count / 4..<count / 4 * 3 {
        samples[i] = (amplitude / 2) - Int16(step * Float(i))
    }
    for i in count / 4 * 3..<count {
        samples[i] = -(amplitude / 2) + Int16(step * Float(i))
    }
}
```

This function is used to generate a triangle wave. The count is the amount of samples in a period. The samples change linearly in stages. No matter whether they increase or decrease, the variation is always the same and decided by the step.

All samples are calculated into three parts: 
* In the first part, the samples gradually increase to half amplitude. The increment is decided by the step.
* In the second part, the samples decrease from half amplitude to minus half amplitude. 
* In the third part, the samples go up from minus half amplitude.

<img
  src={require('./img/generateTriangleWave.png').default}
  alt="Generate triangle wave" width="720"
/>

```swift
func playWave(samples: [Int16], frequency: Float, duration: Float) {
    let playCount = Int(duration * Float(sampleRate))
    var data = [Int16](repeating: 0, count: playCount)

    let step: Float = frequency * Float(samples.count) / Float(sampleRate)

    var volume: Float = 1.0
    let volumeStep = 1.0 / Float(playCount)

    for i in 0..<playCount {
        let pos = Int(Float(i) * step) % samples.count 
        data[i] = Int16(Float(samples[pos]) * volume)
        volume -= volumeStep
    }
    data.withUnsafeBytes { ptr in
        let u8Array = ptr.bindMemory(to: UInt8.self)
        speaker.write(Array(u8Array))
    }
}
```

This function is what you use to play the audio using the generated sample.
* playCount calculates the total amount of samples. sampleRate is the amount in 1s and the duration is a specified time. Then you will get an array data with a given count of samples.
* To better understand the step, let’s look at an example. Let’s suppose a square wave. You get a sample of its first period. The count of samples is 1000. The frequency of the signal is 200. So there will be 200000 samples in total in one second. If the sample rate is at 10000, it needs only this amount of samples in one second. Then you can get 1 sample every 2 samples, like samples[0], samples[2]...So the step here is 2. In brief, the step decides how the sample is used.

<img
  src={require('./img/step.png').default}
  alt="Step" width="480"
/>

* volume and volumeStep are used to gradually reduce the volume of each note and make the sound softer. You can try to delete them and see how it sounds. The sound will be stronger.  
* In the for-in loop, you will get the data from samples. The whole samples are just repetitions of those in the first period. pos gets the index of the sample in samples by getting a remainder. So the value of data[i] actually equals an element in samples multiplied by volume.
* Send the data using I2S communication so that the speaker plays the note.


## More info
* [Digital audio](https://www.joelstrait.com/digital_audio_primer/)