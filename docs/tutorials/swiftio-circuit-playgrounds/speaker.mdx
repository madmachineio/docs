---
title: Play music with a speaker
description: Learn how to
---

# Play music with a speaker

In this tutorial, let's learn something about audio. You'll play a piece of music using a speaker.

You have tried to produce sound using a buzzer. It sounds indeed so sharp. So this time, you are going to enjoy the music played by the speaker. It provides a higher audio quality.

**Learning goals**
* Learn how the speaker produces different sounds.
* Understand the difference between buzzer and speaker.
* Have a general idea of I2S.
* Know about different sound waveforms.
* Learn about audio sampling.
* Realize the difference between WAVE and MP3 files.

## ðŸ”¸Background

### What is I2S?

**I2S**, short for inter-integrated circuit sound, is specially designed for audio data transmission. It uses three wires for communication:

* **SCK** (Serial clock): or Bit Clock (BCLK), it carries the clock signal. Its clock frequency equals Sample Rate * Bits per channel * Number of channels.
* **FS** (Frame Sync): or Word Select (WS), it tells the audio data being transmitted is for right or left channel.
* **SD** (Serial data): it is used to transfer audio data. 

<img
  src={require('./img/i2s.png').default}
  alt="I2S" width="480"
/>

The SwiftIO Feather board always serves as a master device. There are two I2S interfaces: 
* one is **I2SOut**. It sends out data to other audio devices, like speakers, so the serial data line is TX, used to send data.
* the other is **I2SIn**, and the corresponding serial data line only receives the audio data. It can be used with, for example, microphones to collect sound info.

## ðŸ”¸New concept
### Audio

You listen to music in everyday life, but do you know how audio is stored on your computer? Besides, there are so many different file formats, whatâ€™s their difference? Letâ€™s find out more about it.

**Waveform**

The waveforms of sound are various. Sine wave, square wave, triangle wave, and sawtooth wave are the four commonly used forms. The [sounds](https://www.perfectcircuit.com/signal/difference-between-waveforms) produced by them are quite different. The combinations of different waveforms can produce really amazing sounds.  

<img
  src={require('./img/waveforms.png').default}
  alt="Wave forms" width="960"
/>

Weâ€™ll talk about the sine wave in following part and only deal with periodic waveforms. Sine wave is the fundamental waveform. Other period waveforms can be divided into several different sine waves. 

A periodic waveform repeats the wave in a period and produces constant sound. The **frequency** measures how many times the wave repeats in a second, measured in hertz (hz). The wave below repeats the minimum wave 5 times, so the frequency is 5Hz. The higher the frequency, the higher the pitch. The frequencies of human hearing are about 20Hz to 20kHz. 

<img
  src={require('./img/sineWave.png').default}
  alt="Sine wave" width="480"
/>

**Sampling**

The audio signal is analog and the data always change with time. There are some sampling techniques to store the data digitally. Letâ€™s take a look at the one called **pulse code modulation** (PCM). Briefly speaking, it records the sound amplitudes at a regular time interval. Then the samples will be encoded into digital values. As long as the sample data are enough, you could largely recreate the original audio signal. 

<img
  src={require('./img/sampling.png').default}
  alt="Sampling" width="480"
/>

**Sample rate** describes how many times the signal is sampled in one second, measured in hertz (hz). There is a known law about the sample rate: it should be more than twice the original sound frequency, or it will cause distortion.

**Sample depth** corresponds to the number of possible values between the minimum and maximum sound. The common choices are 16, 24, 32-bit. The higher the sample depth, the more audio data will be stored, so the sound will more likely to be reproduced.

When you wear headphones to listen to music, you can hear sounds in your left and right ear. This audio is called stereo. It has two channels: **left channel and right channel**. The two channels have different waveforms. 

Since the maximum frequency for human ears is about 20KHz, the sample rate should be double, that is, about 40KHz. The CD audio is sampled at 44,100Hz, that means there are 44100 sampled signals in a second, so this rate is widely used for all kinds of audio material. And it is usually sampled as 16-bit and has two channels. 

**Audio format**

There are many audio formats that you can see when you listen to music: mp3, wave, aac, flacâ€¦ Different formats will affect the sound quality when you hear it. Wave and flac are lossless audio formats, while mp3 and aac are lossy formats. Letâ€™s talk about the two common formats: wav and mp3.

Wave file contains not only a list of raw samples, but also a header in front to indicate the information about sampling. It stores the original audio data as they are. So the WAV file has no data loss and doesnâ€™t require decoding. However, it is large in size as it keeps all the audio data.

MP3 files use some compression algorithms to remove some of the frequencies that human ears are not sensitive to. And to many of the listeners, this quality loss is not perceptible. Compared to the wav file, MP3 is much smaller and is really handy to download from the Internet. Since it uses compression algorithms, the file needs to be decoded to play it.  

## ðŸ”¸New component

### Speaker

The working principle of the speaker is similar to the buzzer. When the current flows, the internal diaphragm would move back and forth, thus causing the air vibration which leads to the sound you hear. The differences between speaker and buzzer lie in that the diaphragm inside a speaker would move to different positions according to the signal, so the speaker could produce multiple sounds, also, the sound is of higher quality. So the speaker is suitable to reproduce the audio signal it receives and is widely used to play music. 

Symbol: 

The speaker needs an analog signal to produce sounds. The audio info transmitted through the I2S bus is a digital signal. It is not the signal that the speaker requires, so there is an additional chip beside the speaker that could convert the digital signal to an analog signal, known as DAC. 

Even after successfully converted to an analog signal, the audio signal is not strong enough to drive a speaker and could only drive a headphone. So there comes an amplifier. It could make the signal appropriate for the speaker. In this way, the speaker finally plays the music.

Letâ€™s find out how the audio is generated by the speaker. 

* First, you get a WAV file, not an MP3 file. The WAV file is uncompressed and stores the raw audio info, while the MP3 file adopts some technique to compress the audio and reserves the overall audio quality.  Weâ€™ll find it more in the next chapter. 
* Then the microcontroller reads the audio file and gets the data.
* The audio signal is transmitted on the I2S bus, then converted to an analog signal and amplified for the speaker. At last, you hear the music from the speaker. 

## ðŸ”¸Circuit

The speaker is connected to I2SOut0.

<img
  src={require('./img/speakerCircuit.png').default}
  alt="Speaker circuit" width="960"
/>

<img
  src={require('./img/speakerCircuitDiagram.png').default}
  alt="Speaker circuit diagram" width="360"
/>

:::note
The circuits above are simplified versions for your reference.
:::

## ðŸ”¸Preparation

Class 
I2SOut: this class is used to write audio data to external devices using I2S protocol. 
Method 
init(_ idName: IdName, rate: Int = 16_000, bits: Int = 16, channel: SampleChannel = .monoLeft,
 mode: Mode = .philips)
Initialize an I2S output interface.
The first parameter is the pin id.
The rate decides the sampling rate of the audio. The default rate is 16000 Hz.
The bits is the sampling depth of the audio. It is 16-bit by default.
There are three channels: left, right and stereo. By default, it is .monoLeft.
The mode is about different ways that define how the data is formed. The .philips is the default mode.


write(_ sample: [UInt8], count: Int? = nil, timeout: Int? = nil)
Send audio data out to devices.


## ðŸ”¸Exercise

1. Play scales with different sounds


### 1. Play scales with different sounds

Different waveforms can generate different sounds. In this exercise, you will generate a square wave and a triangle wave manually. Then play the scale using two sounds.

<img
  src={require('./img/music.png').default}
  alt="Music" width="480"
/>

**Code analysis**
You can find the complete code here. 

```swift
import SwiftIO
import SwiftIOFeather
```

Import the SwiftIO library to set I2S and the SwiftIOFeather to use pin ids.

```swift
let speaker = I2SOut(Id.I2SOut0)
```

Initialize an I2SOut interface reserved for the speaker. It will have a 16k sample rate and 16-bit sample bits by default.

```swift
let frequency: [Float] = [261.626, 293.665, 329.628, 349.228, 391.995, 440.000, 493.883]
```

Store frequencies for note C, D, E, F, G, A, B. That constitutes a scale.

```swift
let sampleRate = 16_000
let rawSampleLength = 1000
var rawSamples = [Int16](repeating: 0, count: rawSampleLength)
var amplitude: Int16 = 20_000
```

Define the parameters for the audio data: 

* The signal is sampled at 16000 Hz, so there will be 16000 data 1 second.
* rawSampleLength decides the count of samples of the generated waves. 
* rawSamples stores the samples of the audio signal. At first, all values are filled with 0 and the count is decided by rawSampleLength.
* amplitude is the difference between the minimum and maximum.

```swift
while true {

    let duration: Float = 1.0

    generateSquare(amplitude: amplitude, &rawSamples)
    for f in frequency {
        playWave(samples: rawSamples, frequency: f, duration: duration)
    } 
    sleep(ms: 1000)

    generateTriangle(amplitude: amplitude, &rawSamples)
    for f in frequency {
        playWave(samples: rawSamples, frequency: f, duration: duration)
    } 
    sleep(ms: 1000)

    amplitude -= 2000
    if amplitude <= 0 {
        amplitude = 20_000
    }
}
```

In the loop, you will always play scales. The pitch is decided by the frequencies. How the samples sound is decided by the wave form. 

The first time, itâ€™s a square wave, the sound is like the one you hear from a buzzer. After that, itâ€™s a triangle wave, the sound is softer and clearer.  Then the amplitude decreases and will turn down the speaker.

```swift
func generateSquare(amplitude: Int16, _ samples: inout [Int16]) {
    let count = samples.count
    for i in 0..<count / 2 {
        samples[i] = -(amplitude / 2)
    }
    for i in count / 2..<count {
        samples[i] = amplitude / 2
    }
}
```

This function allows you to generate a square wave as below. It will calculate the samples in a period and store them, thus the array samples is set as inout and can be changed inside the function. When you play the audio, the following waves just repeat these samples.

The signal just has two states, so the calculation is quite simple. The first half samples are all the minimum and the second half are all the maximum.

<img
  src={require('./img/generateSquareWave.png').default}
  alt="Generate square wave" width="720"
/>

```swift
func generateTriangle(amplitude: Int16, _ samples: inout [Int16]) {
    let count = samples.count

    let step = Float(amplitude) / Float(count)
    for i in 0..<count / 4{
        samples[i] = Int16(step * Float(i))
    }
    for i in count / 4..<count / 4 * 3 {
        samples[i] = (amplitude / 2) - Int16(step * Float(i))
    }
    for i in count / 4 * 3..<count {
        samples[i] = -(amplitude / 2) + Int16(step * Float(i))
    }
}
```

This function is used to generate a triangle wave. The count is the amount of samples in a period. The samples change linearly in stages. No matter whether they increase or decrease, the variation is always the same and decided by the step.

All samples are calculated into three parts: 
* In the first part, the samples gradually increase to half amplitude. The increment is decided by the step.
* In the second part, the samples decrease from half amplitude to minus half amplitude. 
* In the third part, the samples go up from minus half amplitude.

<img
  src={require('./img/generateTriangleWave.png').default}
  alt="Generate triangle wave" width="720"
/>

```swift
func playWave(samples: [Int16], frequency: Float, duration: Float) {
    let playCount = Int(duration * Float(sampleRate))
    var data = [Int16](repeating: 0, count: playCount)

    let step: Float = frequency * Float(samples.count) / Float(sampleRate)

    var volume: Float = 1.0
    let volumeStep = 1.0 / Float(playCount)

    for i in 0..<playCount {
        let pos = Int(Float(i) * step) % samples.count 
        data[i] = Int16(Float(samples[pos]) * volume)
        volume -= volumeStep
    }
    data.withUnsafeBytes { ptr in
        let u8Array = ptr.bindMemory(to: UInt8.self)
        speaker.write(Array(u8Array))
    }
}
```

This function is what you use to play the audio using the generated sample.
* playCount calculates the total amount of samples. sampleRate is the amount in 1s and the duration is a specified time. Then you will get an array data with a given count of samples.
* To better understand the step, letâ€™s look at an example. Letâ€™s suppose a square wave. You get a sample of its first period. The count of samples is 1000. The frequency of the signal is 200. So there will be 200000 samples in total in one second. If the sample rate is at 10000, it needs only this amount of samples in one second. Then you can get 1 sample every 2 samples, like samples[0], samples[2]...So the step here is 2. In brief, the step decides how the sample is used.

<img
  src={require('./img/step.png').default}
  alt="Step" width="480"
/>

* volume and volumeStep are used to gradually reduce the volume of each note and make the sound softer. You can try to delete them and see how it sounds. The sound will be stronger.  
* In the for-in loop, you will get the data from samples. The whole samples are just repetitions of those in the first period. pos gets the index of the sample in samples by getting a remainder. So the value of data[i] actually equals an element in samples multiplied by volume.
* Send the data using I2S communication so that the speaker plays the note.


## ðŸ”¸More info
* [Waveforms](https://pudding.cool/2018/02/waveforms/)
* [Digital audio](https://www.joelstrait.com/digital_audio_primer/)
* [I2S](https://www.allaboutcircuits.com/technical-articles/introduction-to-the-i2s-interface/)